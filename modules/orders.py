# modules/orders.py
# Obs≈Çuga zam√≥wie≈Ñ: pliki + rƒôczne wpisy, z op√≥≈∫nionym przetwarzaniem

import streamlit as st
import pandas as pd
import numpy as np
import traceback
import sys
from modules.ui_strings import STR

# Cache na zam√≥wienia z plik√≥w
if "orders_cache" not in st.session_state:
    st.session_state["orders_cache"] = {
        "files_keys": None,      # identyfikatory plik√≥w
        "orders_all": None,
        "orders_agg": None,
    }

# ---------- Parsowanie pojedynczego pliku zam√≥wie≈Ñ ----------

def parse_order_file_to_df(fobj):
    """
    Czyta pojedynczy plik zam√≥wie≈Ñ (XLSX w formacie z OrderMasterSheet)
    BEZ u≈ºycia pandas.read_excel / openpyxl, ≈ºeby uniknƒÖƒá b≈Çƒôdu wildcard.

    Oczekiwana struktura arkusza OrderMasterSheet:
    - kolumna A: Materialnummer / Nr materiau (ARTIKELNR)
    - kolumna B: Artikelgesamtmenge / Ilo≈õƒá sztuk (ca≈Çkowita ilo≈õƒá)
    - kolumna C: liczba palet (brak nag≈Ç√≥wka)
    - kolumna D: szt./wiƒÖzka
    Reszta kolumn ignorowana.

    Zwraca DataFrame z kolumnami:
      ARTIKELNR (upper), ORDER_PALLETS (int), ORDER_QTY (float)
    """
    import io
    import zipfile
    import xml.etree.ElementTree as ET

    name = getattr(fobj, "name", "uploaded")

    # CSV / TXT ‚Äì –Ω–∞ –±—É–¥—É—â–µ–µ
    if name.lower().endswith((".csv", ".txt")):
        try:
            df_o = pd.read_csv(
                fobj,
                sep=";",
                dtype=str,
                encoding="utf-8",
                header=0,
            )
        except Exception as e:
            print("\n===== ORDER PARSE ERROR (CSV/TXT) =====", file=sys.stderr)
            traceback.print_exc()
            print("===== END ORDER PARSE ERROR =====\n", file=sys.stderr)
            st.error(f"B≈ÇƒÖd czytania pliku zam√≥wienia {name}: {e}")
            return None
        return None

    # ---- XLSX: –Ω–∏–∑–∫–æ—É—Ä–æ–≤–Ω–µ–≤–æ–µ —á—Ç–µ–Ω–∏–µ XML ----
    try:
        fobj.seek(0)
        file_bytes = fobj.read()
        fobj.seek(0)

        with zipfile.ZipFile(io.BytesIO(file_bytes), "r") as zf:
            # workbook.xml ‚Äì szukamy arkusza z zam√≥wieniem
            with zf.open("xl/workbook.xml") as wb:
                wb_tree = ET.parse(wb)
                wb_root = wb_tree.getroot()
            ns = {"ns": "http://schemas.openxmlformats.org/spreadsheetml/2006/main"}

            sheet_id = None
            for sheet in wb_root.findall("ns:sheets/ns:sheet", ns):
                sheet_name = sheet.attrib.get("name", "")
                r_id = sheet.attrib.get("{http://schemas.openxmlformats.org/officeDocument/2006/relationships}id")
                if sheet_name in ("OrderMasterSheet", "Order_Master_Sheet"):
                    sheet_id = r_id
                    break
            if sheet_id is None:
                first_sheet = wb_root.find("ns:sheets/ns:sheet", ns)
                if first_sheet is None:
                    raise ValueError("Brak arkuszy w pliku XLSX")
                sheet_id = first_sheet.attrib.get(
                    "{http://schemas.openxmlformats.org/officeDocument/2006/relationships}id"
                )

            # workbook.xml.rels ‚Äì ≈õcie≈ºka do pliku arkusza
            with zf.open("xl/_rels/workbook.xml.rels") as rels:
                rels_tree = ET.parse(rels)
                rels_root = rels_tree.getroot()
            rel_ns = {"rel": "http://schemas.openxmlformats.org/package/2006/relationships"}

            sheet_path = None
            for rel in rels_root.findall("rel:Relationship", rel_ns):
                if rel.attrib.get("Id") == sheet_id:
                    sheet_path = rel.attrib.get("Target")
                    break
            if sheet_path is None:
                raise ValueError("Nie mo≈ºna znale≈∫ƒá arkusza dla zam√≥wie≈Ñ (rels).")

            if not sheet_path.startswith("xl/"):
                sheet_path = "xl/" + sheet_path

            # XML wybranego arkusza
            with zf.open(sheet_path) as sf:
                sheet_tree = ET.parse(sf)
                sheet_root = sheet_tree.getroot()

            # sharedStrings ‚Äì teksty
            shared_strings = []
            if "xl/sharedStrings.xml" in zf.namelist():
                with zf.open("xl/sharedStrings.xml") as ssf:
                    ss_tree = ET.parse(ssf)
                    ss_root = ss_tree.getroot()
                for si in ss_root.findall("{http://schemas.openxmlformats.org/spreadsheetml/2006/main}si"):
                    t = si.find("{http://schemas.openxmlformats.org/spreadsheetml/2006/main}t")
                    shared_strings.append(t.text if t is not None else "")

            # wiersze + kom√≥rki
            rows_data = []
            for row_elem in sheet_root.findall(
                ".//{http://schemas.openxmlformats.org/spreadsheetml/2006/main}row"
            ):
                row_values = []
                last_col_idx = -1
                for cell in row_elem.findall(
                    "{http://schemas.openxmlformats.org/spreadsheetml/2006/main}c"
                ):
                    cell_ref = cell.attrib.get("r", "")
                    col_letters = "".join(ch for ch in cell_ref if ch.isalpha())
                    col_idx = 0
                    for ch in col_letters:
                        col_idx = col_idx * 26 + (ord(ch.upper()) - ord("A") + 1)
                    col_idx -= 1  # 0-based

                    while last_col_idx + 1 < col_idx:
                        row_values.append("")
                        last_col_idx += 1

                    v = cell.find(
                        "{http://schemas.openxmlformats.org/spreadsheetml/2006/main}v"
                    )
                    cell_type = cell.attrib.get("t")
                    if v is not None and v.text is not None:
                        if cell_type == "s":
                            idx = int(v.text)
                            value = shared_strings[idx] if 0 <= idx < len(shared_strings) else ""
                        else:
                            value = v.text
                    else:
                        value = ""

                    row_values.append(str(value))
                    last_col_idx = col_idx

                if row_values:
                    rows_data.append(row_values)

            if not rows_data:
                raise ValueError("Brak danych w arkuszu zam√≥wie≈Ñ.")

            max_cols = max(len(r) for r in rows_data)
            rows_padded = [r + [""] * (max_cols - len(r)) for r in rows_data]
            df_o = pd.DataFrame(rows_padded)

    except Exception as e:
        print("\n===== ORDER PARSE ERROR (XLSX ZIP/XML) =====", file=sys.stderr)
        traceback.print_exc()
        print("===== END ORDER PARSE ERROR =====\n", file=sys.stderr)
        st.error(f"B≈ÇƒÖd czytania pliku zam√≥wienia {name}: {e}")
        return None

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    if df_o.shape[1] < 4:
        st.error(f"Plik {name} ma za ma≈Ço kolumn (oczekiwane >= 4).")
        return None

    df4 = df_o.iloc[:, :4].copy()

    if df4.shape[0] <= 2:
        st.error(f"Plik {name} ma za ma≈Ço wierszy z danymi.")
        return None

    data = df4.iloc[2:].copy()
    data.columns = ["ARTIKELNR_RAW", "QTY_RAW", "PALLETS_RAW", "PER_RAW"]

    res = pd.DataFrame()
    res["ARTIKELNR"] = data["ARTIKELNR_RAW"].astype(str).str.strip().str.upper()

    res["ORDER_QTY"] = pd.to_numeric(
        data["QTY_RAW"].astype(str).str.replace(",", "."),
        errors="coerce",
    ).fillna(0)

    res["ORDER_PALLETS"] = pd.to_numeric(
        data["PALLETS_RAW"].astype(str).str.replace(",", "."),
        errors="coerce",
    ).fillna(0).astype(int)

    res = res[res["ORDER_PALLETS"] > 0].copy()

    per_vals = pd.to_numeric(
        data["PER_RAW"].astype(str).str.replace(",", "."),
        errors="coerce",
    ).fillna(0)

    missing = (res["ORDER_QTY"] == 0) & (per_vals > 0)
    if missing.any():
        res.loc[missing, "ORDER_QTY"] = (
            res.loc[missing, "ORDER_PALLETS"] * per_vals.loc[missing]
        )

    res["ARTIKELNR"] = res["ARTIKELNR"].astype(str).str.strip()
    res = res[res["ARTIKELNR"] != ""].copy()

    return res

# ---------- Agregacja wielu plik√≥w zam√≥wie≈Ñ ----------

def natural_sort_key(text):
    import re
    parts = re.split(r"(\d+)", str(text).upper())
    return [int(p) if p.isdigit() else p for p in parts]

def aggregate_uploaded_orders(uploaded_orders):
    """
    Przyjmuje listƒô plik√≥w ze st.file_uploader,
    zwraca:
      - orders_all: wszystkie wiersze z plik√≥w (ARTIKELNR, ORDER_PALLETS, ORDER_QTY, SOURCE_FILE)
      - orders_agg: agregat po ARTIKELNR z podsumowaniem ilo≈õci

    Buduje te≈º mapƒô szczeg√≥≈Ç√≥w po artykule: ile sztuk z ka≈ºdego pliku,
    kt√≥ra p√≥≈∫niej jest u≈ºyta do tooltip√≥w w tabeli agregatu.
    """
    # mapa szczeg√≥≈Ç√≥w: ARTIKELNR -> { filename: qty_sum }
    orders_detail_map = {}

    if not uploaded_orders:
        st.session_state["orders_cache"] = {
            "files_keys": None,
            "orders_all": None,
            "orders_agg": None,
            "orders_detail_map": {},
        }
        return None, None

    # prosty identyfikator zestawu plik√≥w: nazwy + rozmiar
    files_keys = tuple((getattr(f, "name", ""), getattr(f, "size", None)) for f in uploaded_orders)

    cache = st.session_state.get("orders_cache", {})
    if (
        cache.get("files_keys") == files_keys
        and cache.get("orders_agg") is not None
        and cache.get("orders_detail_map") is not None
    ):
        # u≈ºyj ju≈º policzonych danych ‚Äì bez ponownego parsowania
        return cache["orders_all"], cache["orders_agg"]

    # je≈õli pliki siƒô zmieni≈Çy ‚Äì licz od nowa
    orders_list = []

    for f in uploaded_orders:
        name = getattr(f, "name", "uploaded")
        parsed = parse_order_file_to_df(f)
        if parsed is None or parsed.empty:
            continue

        # dodaj info o ≈∫r√≥dle do wierszy
        parsed = parsed.copy()
        parsed["SOURCE_FILE"] = name

        # budowa mapy szczeg√≥≈Ç√≥w: suma sztuk z ka≈ºdego pliku dla danego artyku≈Çu
        grouped = parsed.groupby("ARTIKELNR", as_index=False).agg(
            ORDER_PALLETS=("ORDER_PALLETS", "sum"),
            ORDER_QTY=("ORDER_QTY", "sum"),
        )
        for _, row in grouped.iterrows():
            art = str(row["ARTIKELNR"]).strip().upper()
            qty = float(row["ORDER_QTY"])
            if art not in orders_detail_map:
                orders_detail_map[art] = {}
            orders_detail_map[art][name] = orders_detail_map[art].get(name, 0) + qty

        orders_list.append(parsed)

    if not orders_list:
        st.session_state["orders_cache"] = {
            "files_keys": files_keys,
            "orders_all": None,
            "orders_agg": None,
            "orders_detail_map": {},
        }
        return None, None

    # wszystkie wiersze z plik√≥w
    orders_all = pd.concat(orders_list, ignore_index=True)

    # agregat po ARTIKELNR (tylko z plik√≥w, bez rƒôcznych)
    orders_agg = orders_all.groupby("ARTIKELNR", as_index=False).agg(
        ORDER_PALLETS=("ORDER_PALLETS", "sum"),
        ORDER_QTY=("ORDER_QTY", "sum"),
    )

    # tylko artyku≈Çy z paletami > 0
    orders_agg = orders_agg[orders_agg["ORDER_PALLETS"] > 0].copy()

    # naturalna sortowanie po ARTIKELNR
    orders_agg["_sort_key"] = orders_agg["ARTIKELNR"].apply(natural_sort_key)
    orders_agg = orders_agg.sort_values("_sort_key").drop(columns=["_sort_key"]).reset_index(drop=True)

    # zapisz do cache
    st.session_state["orders_cache"] = {
        "files_keys": files_keys,
        "orders_all": orders_all,
        "orders_agg": orders_agg,
        "orders_detail_map": orders_detail_map,
    }

    return orders_all, orders_agg

def make_order_tooltip(art, orders_detail_map, manual_agg):
    lines = []
    a = str(art).strip().upper()

    if a in orders_detail_map:
        for fname, qty in orders_detail_map[a].items():
            if qty != 0:
                lines.append(f"{fname} - {int(qty)} szt.")

    if manual_agg is not None and not manual_agg.empty:
        man_row = manual_agg[manual_agg["ARTIKELNR"] == a]
        if not man_row.empty:
            mq = float(man_row["Manual_Qty"].iloc[0])
            if mq != 0:
                lines.append(f"Dodatkowe zam√≥wienia - {int(mq)} szt.")

    if not lines:
        return "Brak informacji z plik√≥w zam√≥wie≈Ñ"

    return " ; ".join(lines)



# ---------- Rƒôczne zam√≥wienia ‚Äì –±—ã—Å—Ç—Ä—ã–π –¥–æ–∑–∞–∫–∞–∑ –±–µ–∑ —Ç–∞–±–ª–∏—Ü—ã ----------

def init_manual_orders():
    """
    Bufor edytora (manual_orders_editor_df) zawsze ma przynajmniej jeden pusty wiersz.
    Committed ‚Äì to ju≈º dodane do agregatu zam√≥wie≈Ñ.
    """
    if "manual_orders_editor_df" not in st.session_state:
        st.session_state.manual_orders_editor_df = pd.DataFrame(
            {"ARTIKELNR": [""], "ORDER_PALLETS": [0], "ORDER_QTY": [0]}
        )
    if "manual_orders_committed_df" not in st.session_state:
        st.session_state.manual_orders_committed_df = pd.DataFrame(
            {"ARTIKELNR": [], "ORDER_PALLETS": [], "ORDER_QTY": []}
        )

def render_manual_orders_editor(artikel_options):
    """
    Prosty formularz do rƒôcznych zam√≥wie≈Ñ:
      - wprowadzanie jednej pozycji na raz,
      - bufor jest niewidoczny ‚Äì od razu dodajemy do agregatu,
      - lista ju≈º dodanych rƒôcznych zam√≥wie≈Ñ na dole.
    """
    init_manual_orders()

    st.subheader(STR["manual_orders"])

    # 1) Formularz jednej pozycji
    st.markdown("#### Dodaj pojedynczy artyku≈Ç do rƒôcznych zam√≥wie≈Ñ")

    col_a, col_p, col_q, col_btn = st.columns([3, 1, 1, 1])

    with col_a:
        options = [""] + artikel_options
        new_art = st.selectbox(
            "ARTIKELNR",
            options=options,
            index=0,
            key="manual_artikel_select",
        )

    with col_p:
        new_pallets = st.number_input(
            "Palety",
            min_value=0,
            value=0,
            key="manual_pallets_input",
        )

    with col_q:
        new_qty = st.number_input(
            "Ilo≈õƒá sztuk",
            min_value=0,
            value=0,
            key="manual_qty_input",
        )

    with col_btn:
        st.write("")
        if st.button("Dodaj wiersz", key="manual_add_row_btn"):
            # 1) –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ä—Ç–∏–∫—É–ª–∞
            if not new_art or not new_art.strip():
                st.warning("Wybierz ARTIKELNR przed dodaniem.")
            else:
                art_norm = new_art.strip().upper()

                # Pozwalamy na wpisanie rƒôczne artyku≈Çu spoza filtr√≥w:
                # je≈õli nie ma go w artikel_options, tylko ostrzegamy.
                if art_norm not in [a.strip().upper() for a in artikel_options]:
                    st.warning("Ten ARTIKELNR nie jest na li≈õcie filtrowanej, ale zostanie dodany rƒôcznie.")

                # 2) –ü—Ä–æ–≤–µ—Ä–∫–∞ ilo≈õci
                if int(new_pallets) == 0 and int(new_qty) == 0:
                    st.warning("Podaj liczbƒô palet lub ilo≈õƒá sztuk przed dodaniem wiersza.")
                else:
                    # 3) Od razu dodajemy do manual_orders_committed_df
                    new_row = pd.DataFrame(
                        {
                            "ARTIKELNR": [art_norm],
                            "ORDER_PALLETS": [int(new_pallets)],
                            "ORDER_QTY": [int(new_qty)],
                        }
                    )

                    st.session_state.manual_orders_committed_df = pd.concat(
                        [st.session_state.manual_orders_committed_df, new_row],
                        ignore_index=True,
                    )

                    st.success(f"Dodano artyku≈Ç {art_norm} do rƒôcznych zam√≥wie≈Ñ.")


    st.markdown("---")

    # 2) –ö–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –≤—Å–µ—Ö —Ä—É—á–Ω—ã—Ö –∑–∞–∫–∞–∑–æ–≤ (–ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)
    if st.button("üóë Usu≈Ñ wszystkie rƒôczne zam√≥wienia", type="secondary", key="clear_manual_committed"):
        st.session_state.manual_orders_committed_df = pd.DataFrame(
            {"ARTIKELNR": [], "ORDER_PALLETS": [], "ORDER_QTY": []}
        )
        st.success("Wyczyszczono wszystkie rƒôczne zam√≥wienia.")

    st.markdown("#### Rƒôczne zam√≥wienia dodane do agregatu")

    committed = st.session_state.manual_orders_committed_df

    if not committed.empty:
        committed_display = committed.copy()
        committed_display["ARTIKELNR"] = committed_display["ARTIKELNR"].astype(str).str.strip().str.upper()
        committed_display["ORDER_PALLETS"] = pd.to_numeric(
            committed_display["ORDER_PALLETS"], errors="coerce"
        ).fillna(0).astype(int)
        committed_display["ORDER_QTY"] = pd.to_numeric(
            committed_display["ORDER_QTY"], errors="coerce"
        ).fillna(0)

        # –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –≤—ã–±–æ—Ä–æ–º –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
        committed_display["USUN"] = False

        edited = st.data_editor(
            committed_display,
            use_container_width=True,
            hide_index=True,
            key="manual_committed_editor",
            column_config={
                "ARTIKELNR": st.column_config.TextColumn("ARTIKELNR", disabled=True),
                "ORDER_PALLETS": st.column_config.NumberColumn("Palety", disabled=True),
                "ORDER_QTY": st.column_config.NumberColumn("Ilo≈õƒá sztuk", disabled=True),
                "USUN": st.column_config.CheckboxColumn("Usu≈Ñ"),
            },
        )

        col_del_one, col_space = st.columns([1, 3])
        with col_del_one:
            if st.button("üóë Usu≈Ñ zaznaczone wiersze", key="manual_delete_selected_committed"):
                mask_to_keep = ~edited["USUN"].fillna(False)
                st.session_state.manual_orders_committed_df = committed[mask_to_keep].reset_index(drop=True)
                st.success("Usuniƒôto zaznaczone wiersze z rƒôcznych zam√≥wie≈Ñ.")
    else:
        st.info("Brak rƒôcznych zam√≥wie≈Ñ w agregacie.")



# ---------- G≈Ç√≥wna funkcja zak≈Çadki 'Zam√≥wienia' ----------

def render_orders_tab(artikel_options, filtered_pallets_df=None, selected_artikel=None):
    """
    G≈Ç√≥wna funkcja dla analizy palet + zam√≥wie≈Ñ.
    """
    from utils import load_excluded_articles  # ‚Üê –¢–û–õ–¨–ö–û 4 –ø—Ä–æ–±–µ–ª–∞!

    
    # 1) –ü–ï–†–í–´–ô –ë–õ–û–ö: –¢–∞–±–ª–∏—Ü–∞ –ø–∞–ª–ª–µ—Ç + –∏—Ö —Å—É–º–º–∞ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É
    st.subheader("üìã Lista palet")
    
    if filtered_pallets_df is not None and not filtered_pallets_df.empty:
        cols_show = [
            "ARTIKELNR",
            "ARTBEZ1",
            "QUANTITY",
            "LHMNR",
            "ZUSTAND",
            "PLATZ",
            "IN_DATE",
            "IN_TIME",
            "OUT_DATE",
            "OUT_TIME",
        ]

        df_show = filtered_pallets_df[cols_show].sort_values(by="OUT_DATE", ascending=False).reset_index(drop=True)
        
        st.dataframe(df_show, use_container_width=True, hide_index=True)
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ –¥–Ω—è–º (–≤ expanders)
        with st.expander("üìä Szczeg√≥≈Çy przyjƒôƒá i usuniƒôƒá wed≈Çug dnia", expanded=False):
            # 1. –ü—Ä–∏–Ω—è—Ç—ã–µ –ø–∞–ª–ª–µ—Ç—ã –ø–æ –¥–Ω—è–º
            accepted_pallets = filtered_pallets_df[~filtered_pallets_df["IS_DELETED"]].copy()
            
            if not accepted_pallets.empty and selected_artikel:
                daily_accepted = accepted_pallets.groupby(["ARTIKELNR", "IN_DATE"], as_index=False).agg(
                    Palety_przyjƒôte=("LHMNR", "nunique"),
                    Sztuki_przyjƒôte=("QUANTITY", "sum")
                )
                daily_accepted["IN_DATE"] = daily_accepted["IN_DATE"].dt.date
                daily_accepted = daily_accepted[daily_accepted["ARTIKELNR"].isin(selected_artikel)]
                daily_accepted = daily_accepted.sort_values(["ARTIKELNR", "IN_DATE"], ascending=[True, False])
                
                st.subheader("üì• Przyjƒôcia wed≈Çug dnia")
                st.dataframe(daily_accepted, use_container_width=True, hide_index=True)
            elif selected_artikel:
                st.info("Brak przyjƒôtych palet dla wybranego artyku≈Çu.")
            
            # 2. –£–¥–∞–ª—ë–Ω–Ω—ã–µ –ø–∞–ª–ª–µ—Ç—ã –ø–æ –¥–Ω—è–º
            deleted_pallets_daily = filtered_pallets_df[filtered_pallets_df["IS_DELETED"]].copy()
            
            if not deleted_pallets_daily.empty and selected_artikel:
                daily_deleted = deleted_pallets_daily.groupby(["ARTIKELNR", "OUT_DATE"], as_index=False).agg(
                    Palety_usuniƒôte=("LHMNR", "nunique"),
                    Sztuki_usuniƒôte=("QUANTITY", "sum")
                )
                daily_deleted["OUT_DATE"] = daily_deleted["OUT_DATE"].dt.date
                daily_deleted = daily_deleted[daily_deleted["ARTIKELNR"].isin(selected_artikel)]
                daily_deleted = daily_deleted.sort_values(["ARTIKELNR", "OUT_DATE"], ascending=[True, False])
                
                st.markdown("---")
                st.subheader("üóëÔ∏è Usuniƒôcia wed≈Çug dnia")
                st.dataframe(daily_deleted, use_container_width=True, hide_index=True)
            elif selected_artikel:
                st.info("Brak usuniƒôtych palet dla wybranego artyku≈Çu.")
            
            if not selected_artikel:
                st.info("Wybierz artyku≈Ç w filtrach, aby zobaczyƒá szczeg√≥≈ÇowƒÖ tabelƒô po dniach.")


    else:
        st.info("Brak palet w wybranym zakresie filtr√≥w.")


    st.markdown("---")

    # 2) –í–¢–û–†–û–ô –ë–õ–û–ö: Zam√≥wienia (pliki + rƒôczne)
    st.subheader("üì¶ Zam√≥wienia")

    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ –∑–∞–∫–∞–∑–æ–≤
    uploaded_orders = st.file_uploader(
        STR["upload_orders"],
        type=["xlsx", "csv", "txt"],
        accept_multiple_files=True,
        key="orders_uploader",
    )

    orders_all, orders_agg_base = aggregate_uploaded_orders(uploaded_orders)

    # Rƒôczne zam√≥wienia
    render_manual_orders_editor(artikel_options)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö –∑–∞–∫–∞–∑–æ–≤
    manual_df = st.session_state.get("manual_orders_committed_df", pd.DataFrame(
        {"ARTIKELNR": [], "ORDER_PALLETS": [], "ORDER_QTY": []}
    ))

    if orders_agg_base is None and manual_df.empty:
        st.info("Brak danych z plik√≥w zam√≥wie≈Ñ ani z rƒôcznych zam√≥wie≈Ñ.")
        return

    # –ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ + rƒôczne
    manual_agg = None
    if not manual_df.empty:
        m = manual_df.copy()
        m["ARTIKELNR"] = m["ARTIKELNR"].astype(str).str.strip().str.upper()
        m["ORDER_PALLETS"] = pd.to_numeric(m["ORDER_PALLETS"], errors="coerce").fillna(0).astype(int)
        m["ORDER_QTY"] = pd.to_numeric(m["ORDER_QTY"], errors="coerce").fillna(0)

        manual_agg = m.groupby("ARTIKELNR", as_index=False).agg(
            Manual_Pallets=("ORDER_PALLETS", "sum"),
            Manual_Qty=("ORDER_QTY", "sum"),
        )

    # Finalny agregat
    if orders_agg_base is not None:
        orders_agg = orders_agg_base.copy()
    else:
        orders_agg = pd.DataFrame(columns=["ARTIKELNR", "ORDER_PALLETS", "ORDER_QTY"])

    if manual_agg is not None and not manual_agg.empty:
        orders_agg = orders_agg.merge(manual_agg, on="ARTIKELNR", how="outer")
    else:
        orders_agg["Manual_Pallets"] = 0
        orders_agg["Manual_Qty"] = 0

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    for col in ["ORDER_PALLETS", "Manual_Pallets"]:
        orders_agg[col] = pd.to_numeric(orders_agg[col], errors="coerce").fillna(0).astype(int)
    for col in ["ORDER_QTY", "Manual_Qty"]:
        orders_agg[col] = pd.to_numeric(orders_agg[col], errors="coerce").fillna(0)

    orders_agg["Ordered_Pallets_Total"] = orders_agg["ORDER_PALLETS"] + orders_agg["Manual_Pallets"]
    orders_agg["Ordered_Qty_Total"] = orders_agg["ORDER_QTY"] + orders_agg["Manual_Qty"]

    # ≈πr√≥d≈Ça
    cache = st.session_state.get("orders_cache", {})
    orders_detail_map = cache.get("orders_detail_map", {})

    def sources_count(row):
        art = str(row["ARTIKELNR"]).strip().upper()
        files_sources = sum(1 for _, qty in orders_detail_map.get(art, {}).items() if qty != 0)
        manual_source = 1 if row.get("Manual_Qty", 0) > 0 else 0
        return files_sources + manual_source

    def is_excluded_article(art, excluded_exact, excluded_prefixes):
        art = str(art).strip().upper()
        if art in [e.upper() for e in excluded_exact]:
            return True
        for p in excluded_prefixes:
            if art.startswith(p.upper()):
                return True
        return False

    orders_agg["≈πr√≥d≈Ça"] = orders_agg.apply(sources_count, axis=1)
    orders_agg["ORDER_TOOLTIP"] = orders_agg["ARTIKELNR"].apply(
        lambda a: make_order_tooltip(a, orders_detail_map, manual_agg)
    )

    # –¢–∞–±–ª–∏—Ü–∞ –∑–∞–∫–∞–∑–æ–≤
    st.subheader("üìã Podsumowanie zam√≥wie≈Ñ (agregat)")
    display_cols = ["ARTIKELNR", "Ordered_Pallets_Total", "Ordered_Qty_Total", "≈πr√≥d≈Ça", "ORDER_TOOLTIP"]
    display_df = orders_agg[display_cols].copy()
    display_df.rename(columns={
        "ARTIKELNR": "ARTIKELNR",
        "Ordered_Pallets_Total": "Zam√≥wione_palety",
        "Ordered_Qty_Total": "Zam√≥wione_sztuki",
        "ORDER_TOOLTIP": "Szczeg√≥≈Çy_≈∫r√≥de≈Ç",
    }, inplace=True)

    st.dataframe(
        display_df,
        use_container_width=True,
        hide_index=True,
    )

    # 3) –°–†–ê–í–ù–ï–ù–ò–ï (–µ—Å–ª–∏ –µ—Å—Ç—å –ø–∞–ª–µ—Ç—ã)
    if filtered_pallets_df is not None and not filtered_pallets_df.empty:
        st.markdown("---")
        st.subheader("‚öñÔ∏è Por√≥wnanie zam√≥wie≈Ñ z usuniƒôtymi paletami")

        deleted_pallets = filtered_pallets_df[filtered_pallets_df["IS_DELETED"]].copy()

        if not deleted_pallets.empty:
            deleted_agg = deleted_pallets.groupby("ARTIKELNR", as_index=False).agg(
                Deleted_Pallets=("LHMNR", "nunique"),
                Deleted_Qty=("QUANTITY", "sum"),
            )

            comparison_df = orders_agg[["ARTIKELNR", "Ordered_Pallets_Total", "Ordered_Qty_Total"]].merge(
                deleted_agg, on="ARTIKELNR", how="outer"
            ).fillna(0)

            comparison_df["R√≥≈ºnica_Palety"] = (
                comparison_df["Ordered_Pallets_Total"] - comparison_df["Deleted_Pallets"]
            )
            comparison_df["R√≥≈ºnica_Sztuki"] = (
                comparison_df["Ordered_Qty_Total"] - comparison_df["Deleted_Qty"]
            )

            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å—Ç—Ä–æ–∫ –±–µ–∑ —Ä–∞–∑–Ω–∏—Ü—ã
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
            excluded_exact, excluded_prefixes = load_excluded_articles()
            
            def should_show_row(row):
                art = row["ARTIKELNR"].strip().upper()
                if is_excluded_article(art, excluded_exact, excluded_prefixes):
                    # –ò—Å–∫–ª—é—á–µ–Ω–∏—è: –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –û–ë–ï —Ä–∞–∑–Ω–∏—Ü—ã –ù–ï –Ω–æ–ª—å
                    return (row["R√≥≈ºnica_Palety"] != 0) and (row["R√≥≈ºnica_Sztuki"] != 0)
                else:
                    # –û–±—ã—á–Ω—ã–µ: –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –µ—Å–ª–∏ –•–û–¢–¨ –û–î–ù–ê —Ä–∞–∑–Ω–∏—Ü–∞
                    return (row["R√≥≈ºnica_Palety"] != 0) or (row["R√≥≈ºnica_Sztuki"] != 0)
            
            comparison_df = comparison_df[comparison_df.apply(should_show_row, axis=1)]


            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –ø–æ—è—Å–Ω–µ–Ω–∏–µ–º
            def explain_diff(row):
                diff_pal = row["R√≥≈ºnica_Palety"]
                diff_szt = row["R√≥≈ºnica_Sztuki"]

                if diff_pal == 0 and diff_szt == 0:
                    return "Brak r√≥≈ºnicy"
                msgs = []

                if diff_pal > 0:
                    msgs.append(f"Usuniƒôto {int(abs(diff_pal))} palet mniej")
                elif diff_pal < 0:
                    msgs.append(f"Usuniƒôto {int(abs(diff_pal))} palet wiƒôcej")
                else:
                    msgs.append("Brak r√≥≈ºnicy w liczbie palet")

                if diff_szt > 0:
                    msgs.append(f"zabrak≈Ço {int(abs(diff_szt))} sztuk")
                elif diff_szt < 0:
                    msgs.append(f"jest {int(abs(diff_szt))} sztuk za du≈ºo")
                else:
                    msgs.append("brak r√≥≈ºnicy w ilo≈õci sztuk")

                return ", ".join(msgs)

            comparison_df["Wyja≈õnienie r√≥≈ºnicy"] = comparison_df.apply(explain_diff, axis=1)

            comparison_df = comparison_df.sort_values("R√≥≈ºnica_Palety", ascending=False).reset_index(drop=True)

            st.dataframe(
                comparison_df,
                use_container_width=True,
                hide_index=True,
            )

            # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            col1, col2, col3 = st.columns(3)
            col1.metric("Artyku≈Çy z zam√≥wieniami", f"{len(orders_agg[orders_agg['Ordered_Pallets_Total'] > 0])}")
            col2.metric("Artyku≈Çy usuniƒôte", f"{len(deleted_agg)}")
            col3.metric("Artyku≈Çy z rozbie≈ºno≈õciƒÖ", f"{len(comparison_df)}")
        else:
            st.info("Brak usuniƒôtych palet w wybranym zakresie.")
